{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c61061db-ea08-473f-9d7b-1f1cc8af7fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Collecting jieba\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/c6/cb/18eeb235f833b726522d7ebed54f2278ce28ba9438e3135ab0278d9792a2/jieba-0.42.1.tar.gz (19.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 19.2 MB 50.7 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: jieba\n",
      "  Building wheel for jieba (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314476 sha256=048dd1d76c83fdbb3cdceaa74d675d11d47fa06a7e3a902d703c333f77d5b88c\n",
      "  Stored in directory: /home/ma-user/.cache/pip/wheels/86/bc/97/67c05f24b07573fd425039f944f8bc57c8dbc6f2c0bcc046fa\n",
      "Successfully built jieba\n",
      "Installing collected packages: jieba\n",
      "Successfully installed jieba-0.42.1\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Collecting gensim\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/9f/10/0a737b7f935a14ac49d12187530952805978e1be506212b7c66d15962e27/gensim-4.2.0-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (24.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.0 MB 51.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages (from gensim) (1.17.5)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/3e/07/36678c6ff0dfa6cf445d0e00bf4f013de3b86ec1a2e8bfd1e5df69b2d91d/smart_open-6.2.0-py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 24.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages (from gensim) (1.5.4)\n",
      "Installing collected packages: smart-open, gensim\n",
      "Successfully installed gensim-4.2.0 smart-open-6.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install jieba\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e345915-b75f-4737-bfc4-ab3a09a4a5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8138dfb-9531-437b-90db-e342964712c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def un_gz(file_name):\n",
    "    \n",
    "    # 获取文件的名称，去掉后缀名\n",
    "    f_name = file_name.replace(\".gz\", \"\")\n",
    "    # 开始解压\n",
    "    g_file = gzip.GzipFile(file_name)\n",
    "    #读取解压后的文件，并写入去掉后缀名的同名文件（即得到解压后的文件）\n",
    "    open(f_name, \"wb+\").write(g_file.read())\n",
    "    g_file.close()\n",
    "    \n",
    "un_gz('tencent-ailab-embedding-zh-d100-v0.2.0-s.tar 1.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2e2d16c-6819-431d-bbad-736f4ed7c4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def untar(fname, dirs):\n",
    "  t = tarfile.open(fname)\n",
    "  t.extractall(path = dirs)\n",
    "\n",
    "untar(\"tencent-ailab-embedding.tar\", \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1ce7808-e0e5-4c64-bddf-d808740f55f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from itertools import chain\n",
    "# import gensim\n",
    "import numpy as np\n",
    "import mindspore\n",
    "from mindspore.mindrecord import FileWriter\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82139a40-5102-4ad8-bf92-64faeabe1897",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 1.489 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "train = pd.read_csv(r'data.txt', header=None, sep=',')\n",
    "real_test = pd.read_csv(r'test.txt', header=None, sep='\\t')\n",
    "train.columns = ['label', 'sentence']\n",
    "real_test.columns = ['sentence']\n",
    "\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    train['sentence'].apply(lambda w: ' '.join(jieba.cut(w))), train['label'], train_size=0.8, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c6204c1-b02f-47f0-b7c3-0a5bcb5a6440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9310     有点 坑爹 ， 点 了 三份 牛肉 只放 了 一份 ， 点 了 2 分 鹌鹑蛋 只放 了 一...\n",
       "5421     两次 了 都 送错 粉 ， 下单 是 牛腩 粉 ， 送餐 的 单子 写 的 大 排粉 ， 实...\n",
       "4549                                      有点 淡 ， 实在 量 太小 了\n",
       "9610                                   我 的 发票 呢 ？ 为什么 没有 啊\n",
       "5579                                             等 了 70 分钟\n",
       "                               ...                        \n",
       "4859                  外卖 员 太 差劲 了 。 , 速度慢 ， , 豆浆 还 没 给 我 。\n",
       "3264                                          这次 不错 ， 赞 一个\n",
       "9845                                   味道 很 一般 ， 比老车 记 差远了\n",
       "10799                                     单子 打错 了 ， 少送 了 。\n",
       "2732                                 快递 师傅 态度 超好 ， 速度 一流 。\n",
       "Name: sentence, Length: 8789, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c9149ad-7213-4d1f-be85-a56f7847761a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_imdb(path, seg='train'):\n",
    "    labels = ['pos', 'neg']\n",
    "    data = []\n",
    "    for label in labels:\n",
    "        files = os.listdir(os.path.join(path, seg, label))\n",
    "        for file in files:\n",
    "            with open(os.path.join(path, seg, label, file), 'r', encoding='utf8') as rf:\n",
    "                review = rf.read().replace('\\n', '')\n",
    "                if label == 'pos':\n",
    "                    data.append([review, 1])\n",
    "                elif label == 'neg':\n",
    "                    data.append([review, 0])\n",
    "    return data\n",
    "\n",
    "def tokenize_samples(raw_data):\n",
    "    tokenized_data = []\n",
    "    for review in raw_data:\n",
    "        tokenized_data.append([tok.lower() for tok in review.split()])\n",
    "    return tokenized_data\n",
    "\n",
    "def encode_samples(tokenized_samples, word_to_idx):\n",
    "    \"\"\"\n",
    "    tokenized_samples: [[word, word, ...]]\n",
    "    word_to_idx: {word:idx, word:idx, ...}\n",
    "    features: [[idx, idx, ...], [idx, idx, ...], ...]\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    for sample in tokenized_samples:\n",
    "        feature = []\n",
    "        for token in sample:\n",
    "            feature.append(word_to_idx.get(token, 0))\n",
    "        features.append(feature)\n",
    "    return features\n",
    "\n",
    "def pad_samples(features, maxlen=500, pad=0):\n",
    "    padded_features = []\n",
    "    for feature in features:\n",
    "        if len(feature) >= maxlen:\n",
    "            padded_feature = feature[:maxlen]\n",
    "        else:\n",
    "            padded_feature = feature\n",
    "            while len(padded_feature) < maxlen:\n",
    "                padded_feature.append(pad)\n",
    "        padded_features.append(padded_feature)\n",
    "    return padded_features\n",
    "\n",
    "def prepare_data(imdb_data_path='./data/imdb/aclImdb'):      \n",
    "    # raw_data_train = read_imdb(imdb_data_path, seg='train')\n",
    "    # raw_data_test = read_imdb(imdb_data_path, seg='test')\n",
    "    # y_train = np.array([label for _, label in raw_data_train]).astype(np.int32)\n",
    "    # y_test = np.array([label for _, label in raw_data_test]).astype(np.int32)    \n",
    "    # tokenized_data_train = tokenize_samples([review for review, _ in raw_data_train])\n",
    "    # tokenized_data_test = tokenize_samples([review for review, _ in raw_data_test])\n",
    "    \n",
    "    tokenized_data_train = tokenize_samples(X_train_text)\n",
    "    tokenized_data_test = tokenize_samples(X_test_text)    \n",
    "    vocab = set(chain(*tokenized_data_train))\n",
    "    word_to_idx = {word: i+1 for i, word in enumerate(vocab)}\n",
    "    word_to_idx['<unk>'] = 0\n",
    "    X_train = np.array(pad_samples(encode_samples(tokenized_data_train, word_to_idx))).astype(np.int32)\n",
    "    X_test = np.array(pad_samples(encode_samples(tokenized_data_test, word_to_idx))).astype(np.int32)\n",
    "    return X_train, y_train, X_test, y_test, word_to_idx\n",
    "\n",
    "X_train, y_train, X_test, y_test, word_to_idx = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1b986b0-bf30-46ca-aecc-0daaedcbc4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_real_test_text=real_test['sentence'].apply(lambda w: ' '.join(jieba.cut(w)))\n",
    "tokenized_data_real_test = tokenize_samples(X_real_test_text)\n",
    "X_real_test=np.array(pad_samples(encode_samples(tokenized_data_real_test, word_to_idx))).astype(np.int32)\n",
    "# y_real_test=train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf307724-6482-453d-a23f-3e259d74dd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_data_train = tokenize_samples(X_train_text)\n",
    "# tokenized_data_train\n",
    "# word_to_idx\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd282fea-cca7-4979-b776-ee2f65bd7f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2137, 1905, 5624, 5144, 4462, 1704, 3455, 1712, 3420, 7034, 3699,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[7,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3db729fd-92f1-4196-add8-f36f89ea0fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ma-user/work'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5a777d0-cb20-4f12-881b-0ccf4b964610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# glove_file_path=r'./embedding/tencent-ailab-embedding.txt'\n",
    "# word2vector=gensim.models.KeyedVectors.load_word2vec_format(glove_file_path,binary=False)\n",
    "# word2vector.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e864741-1f56-442c-a8db-eb29da72972b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!sed -i '1i\\400000 50' ./data/glove/glove.6B.50d.txt\n",
    "def load_embeddings(glove_file_path, word_to_idx, embed_size=100):\n",
    "    word2vector = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "        glove_file_path, binary=False, encoding='utf-8')\n",
    "    assert embed_size == word2vector.vector_size\n",
    "    embeddings = np.zeros((len(word_to_idx), embed_size)).astype(np.float32)\n",
    "    for word, idx in word_to_idx.items():\n",
    "        try:\n",
    "            embeddings[idx, :] = word2vector.word_vec(word)\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return embeddings\n",
    "# embeddings = load_embeddings('./data/glove/glove.6B.50d.txt', word_to_idx)\n",
    "# embeddings = load_embeddings(glove_file_path, word_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3bae8e91-d209-40c7-ab29-317a649a3a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(\"./embedding/weight.txt\", embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e893e1b-7590-40e9-b8ef-eeda0ecaf8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json_data_list(X, y):\n",
    "    data_list = []\n",
    "    for i, (feature, label) in enumerate(zip(X, y)):\n",
    "        data_json = {\"id\": i, \"feature\": feature.reshape(-1), \"label\": int(label)}\n",
    "        data_list.append(data_json)\n",
    "    return data_list\n",
    "\n",
    "def convert_np_to_mindrecord(X_train, y_train, X_test, y_test, mindrecord_save_path=\"./mindrecord\"):\n",
    "    schema_json = {\"id\": {\"type\": \"int32\"},\n",
    "                  \"label\": {\"type\": \"int32\"},\n",
    "                  \"feature\": {\"type\": \"int32\", \"shape\": [-1]}}\n",
    "    writer = FileWriter(os.path.join(mindrecord_save_path, \"aclImdb_train.mindrecord\"), shard_num=4)\n",
    "    data_train = get_json_data_list(X_train, y_train)\n",
    "    writer.add_schema(schema_json, \"nlp_schema\")\n",
    "    writer.add_index([\"id\", \"label\"])\n",
    "    writer.write_raw_data(data_train)\n",
    "    writer.commit()\n",
    "    \n",
    "    writer = FileWriter(os.path.join(mindrecord_save_path, \"aclImdb_test.mindrecord\"), shard_num=4)\n",
    "    data_test = get_json_data_list(X_test, y_test)\n",
    "    writer.add_schema(schema_json, \"nlp_schema\")\n",
    "    writer.add_index([\"id\", \"label\"])\n",
    "    writer.write_raw_data(data_test)\n",
    "    writer.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccd0833a-0027-470f-b26a-8e504a259c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9375"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.max()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25c2a70a-1423-4ad5-9024-0573321ee914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert_np_to_mindrecord(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5123c945-3bc7-458d-a2f6-bc30419d285e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.zeros(X_real_test.shape[0])\n",
    "# y_test\n",
    "# np.array([0]*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d964c182-cedd-473b-862a-11d98c2470a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_np_to_mindrecord(X_real_test,np.zeros(X_real_test.shape[0]),X_real_test, np.zeros(X_real_test.shape[0]),\n",
    "                        mindrecord_save_path=\"./mindrecordtest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb772806-962c-40a6-ba5d-7f228c1a70cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8789,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eaa474cf-f2db-4936-963c-f0034806b02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore.dataset as mds\n",
    "def create_dataset(base_path, batch_size, num_epochs, is_train):\n",
    "    columns_list = [\"feature\", \"label\"]\n",
    "    num_consumer = 4\n",
    "    if is_train:\n",
    "        path = os.path.join(base_path, \"aclImdb_train.mindrecord0\")\n",
    "    else:\n",
    "        path = os.path.join(base_path, \"aclImdb_test.mindrecord0\")\n",
    "    dataset = mds.MindDataset(path, columns_list=[\"feature\", \"label\"], num_parallel_workers=4)\n",
    "    dataset = dataset.shuffle(buffer_size=dataset.get_dataset_size())\n",
    "    dataset = dataset.batch(batch_size=batch_size, drop_remainder=True)\n",
    "    dataset = dataset.repeat(count=num_epochs)\n",
    "    return dataset\n",
    "dataset_train = create_dataset(\"./mindrecord\", batch_size=32, num_epochs=10, is_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22d1feb6-7e56-485f-8293-9faa415417f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2020 Huawei Technologies Co., Ltd\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ============================================================================\n",
    "\"\"\"LSTM.\"\"\"\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from mindspore import Tensor, nn, context, Parameter, ParameterTuple\n",
    "from mindspore.common.initializer import initializer\n",
    "from mindspore.ops import operations as P\n",
    "\n",
    "STACK_LSTM_DEVICE = [\"CPU\"]\n",
    "\n",
    "\n",
    "# Initialize short-term memory (h) and long-term memory (c) to 0\n",
    "def lstm_default_state(batch_size, hidden_size, num_layers, bidirectional):\n",
    "    \"\"\"init default input.\"\"\"\n",
    "    num_directions = 2 if bidirectional else 1\n",
    "    h = Tensor(np.zeros((num_layers * num_directions, batch_size, hidden_size)).astype(np.float32))\n",
    "    c = Tensor(np.zeros((num_layers * num_directions, batch_size, hidden_size)).astype(np.float32))\n",
    "    return h, c\n",
    "\n",
    "\n",
    "def stack_lstm_default_state(batch_size, hidden_size, num_layers, bidirectional):\n",
    "    \"\"\"init default input.\"\"\"\n",
    "    num_directions = 2 if bidirectional else 1\n",
    "\n",
    "    h_list = c_list = []\n",
    "    for _ in range(num_layers):\n",
    "        h_list.append(Tensor(np.zeros((num_directions, batch_size, hidden_size)).astype(np.float32)))\n",
    "        c_list.append(Tensor(np.zeros((num_directions, batch_size, hidden_size)).astype(np.float32)))\n",
    "    h, c = tuple(h_list), tuple(c_list)\n",
    "    return h, c\n",
    "\n",
    "\n",
    "class StackLSTM(nn.Cell):\n",
    "    \"\"\"\n",
    "    Stack multi-layers LSTM together.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 hidden_size,\n",
    "                 num_layers=1,\n",
    "                 has_bias=True,\n",
    "                 batch_first=False,\n",
    "                 dropout=0.0,\n",
    "                 bidirectional=False):\n",
    "        super(StackLSTM, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_first = batch_first\n",
    "        self.transpose = P.Transpose()\n",
    "\n",
    "        # direction number\n",
    "        num_directions = 2 if bidirectional else 1\n",
    "\n",
    "        # input_size list\n",
    "        input_size_list = [input_size]\n",
    "        for i in range(num_layers - 1):\n",
    "            input_size_list.append(hidden_size * num_directions)\n",
    "\n",
    "        # layers\n",
    "        layers = []\n",
    "        for i in range(num_layers):\n",
    "            layers.append(nn.LSTM(input_size=input_size_list[i],\n",
    "                                      hidden_size=hidden_size,\n",
    "                                      has_bias=has_bias,\n",
    "                                      batch_first=batch_first,\n",
    "                                      bidirectional=bidirectional,\n",
    "                                      dropout=dropout))\n",
    "\n",
    "        # weights\n",
    "        weights = []\n",
    "        for i in range(num_layers):\n",
    "            # weight size\n",
    "            weight_size = (input_size_list[i] + hidden_size) * num_directions * hidden_size * 4\n",
    "            if has_bias:\n",
    "                bias_size = num_directions * hidden_size * 4\n",
    "                weight_size = weight_size + bias_size\n",
    "\n",
    "            # numpy weight\n",
    "            stdv = 1 / math.sqrt(hidden_size)\n",
    "            w_np = np.random.uniform(-stdv, stdv, (weight_size, 1, 1)).astype(np.float32)\n",
    "\n",
    "            # lstm weight\n",
    "            weights.append(Parameter(initializer(Tensor(w_np), w_np.shape), name=\"weight\" + str(i)))\n",
    "\n",
    "        #\n",
    "        self.lstms = layers\n",
    "        self.weight = ParameterTuple(tuple(weights))\n",
    "\n",
    "    def construct(self, x, hx):\n",
    "        \"\"\"construct\"\"\"\n",
    "        if self.batch_first:\n",
    "            x = self.transpose(x, (1, 0, 2))\n",
    "        # stack lstm\n",
    "        h, c = hx\n",
    "        hn = cn = None\n",
    "        for i in range(self.num_layers):\n",
    "            x, hn, cn, _, _ = self.lstms[i](x, h[i], c[i], self.weight[i])\n",
    "        if self.batch_first:\n",
    "            x = self.transpose(x, (1, 0, 2))\n",
    "        return x, (hn, cn)\n",
    "\n",
    "\n",
    "class SentimentNet(nn.Cell):\n",
    "    \"\"\"Sentiment network structure.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 embed_size,\n",
    "                 num_hiddens,\n",
    "                 num_layers,\n",
    "                 bidirectional,\n",
    "                 num_classes,\n",
    "                 weight,\n",
    "                 batch_size):\n",
    "        super(SentimentNet, self).__init__()\n",
    "        # Mapp words to vectors\n",
    "        self.embedding = nn.Embedding(vocab_size,\n",
    "                                      embed_size,\n",
    "                                      embedding_table=weight)\n",
    "        self.embedding.embedding_table.requires_grad = False\n",
    "        self.trans = P.Transpose()\n",
    "        self.perm = (1, 0, 2)\n",
    "\n",
    "        if context.get_context(\"device_target\") in STACK_LSTM_DEVICE:\n",
    "            # stack lstm by user\n",
    "            self.encoder = StackLSTM(input_size=embed_size,\n",
    "                                     hidden_size=num_hiddens,\n",
    "                                     num_layers=num_layers,\n",
    "                                     has_bias=True,\n",
    "                                     bidirectional=bidirectional,\n",
    "                                     dropout=0.0)\n",
    "            self.h, self.c = stack_lstm_default_state(batch_size, num_hiddens, num_layers, bidirectional)\n",
    "        else:\n",
    "            # standard lstm\n",
    "            self.encoder = nn.LSTM(input_size=embed_size,\n",
    "                                   hidden_size=num_hiddens,\n",
    "                                   num_layers=num_layers,\n",
    "                                   has_bias=True,\n",
    "                                   bidirectional=bidirectional,\n",
    "                                   dropout=0.0)\n",
    "            self.h, self.c = lstm_default_state(batch_size, num_hiddens, num_layers, bidirectional)\n",
    "\n",
    "        self.concat = P.Concat(1)\n",
    "        if bidirectional:\n",
    "            self.decoder = nn.Dense(num_hiddens * 4, num_classes)\n",
    "        else:\n",
    "            self.decoder = nn.Dense(num_hiddens * 2, num_classes)\n",
    "\n",
    "    def construct(self, inputs):\n",
    "        # input：(64,500,300)\n",
    "        embeddings = self.embedding(inputs)\n",
    "        embeddings = self.trans(embeddings, self.perm)\n",
    "        output, _ = self.encoder(embeddings, (self.h, self.c))\n",
    "        # states[i] size(64,200)  -> encoding.size(64,400)\n",
    "        encoding = self.concat((output[0], output[499]))\n",
    "        outputs = self.decoder(encoding)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cd50f4e-f984-4396-90e6-f8d4bf19a9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_tabel = np.loadtxt(os.path.join(\"./embedding/\", \"weight.txt\")).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ceeb9774-002c-4412-8beb-fe9b1bcaebbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CRITICAL] PARSER(2095,ffff9c91c780,python):2023-01-15-20:49:15.164.891 [mindspore/ccsrc/pipeline/jit/parse/resolve.cc:158] ResolveParameterObj] The parameter construct_wrapper.689:weight_ih_l0 , its name 'weight_ih_l0' already exists. Please set a unique name for the parameter.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mindspore/ccsrc/pipeline/jit/parse/resolve.cc:158 ResolveParameterObj] The parameter construct_wrapper.689:weight_ih_l0 , its name 'weight_ih_l0' already exists. Please set a unique name for the parameter.\n\n# In file /home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages/mindspore/nn/layer/rnns.py(460)\n        for i in range(self.num_layers):\n        ^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2095/2260462342.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmindspore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRAPH_MODE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_graphs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_target\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"CPU\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint_cb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_sink_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/MindSpore/lib/python3.7/site-packages/mindspore/train/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epoch, train_dataset, callbacks, dataset_sink_mode, sink_size)\u001b[0m\n\u001b[1;32m    904\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m                     \u001b[0mdataset_sink_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_sink_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m                     sink_size=sink_size)\n\u001b[0m\u001b[1;32m    907\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msink_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjit_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/MindSpore/lib/python3.7/site-packages/mindspore/train/model.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/MindSpore/lib/python3.7/site-packages/mindspore/train/model.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, epoch, train_dataset, callbacks, dataset_sink_mode, sink_size)\u001b[0m\n\u001b[1;32m    540\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_reuse_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdataset_sink_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"device_target\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"CPU\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m                 logger.info(\"The CPU cannot support dataset sink mode currently.\"\n",
      "\u001b[0;32m~/anaconda3/envs/MindSpore/lib/python3.7/site-packages/mindspore/train/model.py\u001b[0m in \u001b[0;36m_train_process\u001b[0;34m(self, epoch, train_dataset, list_callback, cb_params)\u001b[0m\n\u001b[1;32m    792\u001b[0m                 \u001b[0mcb_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dataset_element\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_element\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m                 \u001b[0mlist_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnext_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    795\u001b[0m                 \u001b[0mcb_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loss_scale_manager\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loss_scale_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_drop_overflow_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/MindSpore/lib/python3.7/site-packages/mindspore/nn/cell.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    584\u001b[0m                 logger.warning(f\"For 'Cell', it's not support hook function in graph mode. If you want to use hook \"\n\u001b[1;32m    585\u001b[0m                                f\"function, please use context.set_context to set pynative mode.\")\n\u001b[0;32m--> 586\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_and_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/MindSpore/lib/python3.7/site-packages/mindspore/nn/cell.py\u001b[0m in \u001b[0;36mcompile_and_run\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m    962\u001b[0m         \"\"\"\n\u001b[1;32m    963\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_auto_parallel_compile_and_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m         \u001b[0mnew_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/MindSpore/lib/python3.7/site-packages/mindspore/nn/cell.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m    935\u001b[0m         \"\"\"\n\u001b[1;32m    936\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamic_shape_inputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamic_shape_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m             \u001b[0m_cell_graph_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauto_parallel_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_auto_parallel_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_compile_dynamic_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/MindSpore/lib/python3.7/site-packages/mindspore/common/api.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, obj, phase, do_convert, auto_parallel_mode, *args)\u001b[0m\n\u001b[1;32m   1004\u001b[0m         \u001b[0menable_ge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"enable_ge\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_vm_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mindspore/ccsrc/pipeline/jit/parse/resolve.cc:158 ResolveParameterObj] The parameter construct_wrapper.689:weight_ih_l0 , its name 'weight_ih_l0' already exists. Please set a unique name for the parameter.\n\n# In file /home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages/mindspore/nn/layer/rnns.py(460)\n        for i in range(self.num_layers):\n        ^\n"
     ]
    }
   ],
   "source": [
    "from mindspore import Tensor, nn, Model, context, Parameter\n",
    "from mindspore.common.initializer import initializer\n",
    "from mindspore.ops import operations as P\n",
    "from mindspore.nn import Accuracy\n",
    "from mindspore.train.callback import LossMonitor, CheckpointConfig, ModelCheckpoint, TimeMonitor\n",
    "# from mindspore.model_zoo.lstm import SentimentNet\n",
    "\n",
    "network = SentimentNet(vocab_size=embedding_tabel.shape[0],\n",
    "                embed_size=100,\n",
    "                num_hiddens=100,\n",
    "                num_layers=2,\n",
    "                bidirectional=False,\n",
    "                num_classes=2,\n",
    "                weight=Tensor(embedding_tabel),\n",
    "                batch_size=32)\n",
    "\n",
    "loss = nn.SoftmaxCrossEntropyWithLogits( sparse=True)\n",
    "opt = nn.Momentum(network.trainable_params(), 0.1, 0.9)\n",
    "loss_callback = LossMonitor(per_print_times=60)\n",
    "model = Model(network, loss, opt, {'acc': Accuracy()})\n",
    "config_ck = CheckpointConfig(save_checkpoint_steps=390, keep_checkpoint_max=10)\n",
    "checkpoint_cb = ModelCheckpoint(prefix=\"lstm\", directory=\"./model\", config=config_ck)\n",
    "\n",
    "from mindspore import context\n",
    "context.set_context(mode=context.GRAPH_MODE, save_graphs=False, device_target=\"CPU\")\n",
    "model.train(1, dataset_train, callbacks=[checkpoint_cb, loss_callback], dataset_sink_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a36697-ecac-48be-969d-e0dddf9e80e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a88ba57-eda1-43f8-a862-ff1a4bda7a37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
